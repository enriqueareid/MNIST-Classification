{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "from random import randint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "torch.set_printoptions(precision=8)\n",
    "\n",
    "# Printing Options\n",
    "class designer:\n",
    "    purple = '\\033[95m'\n",
    "    green = '\\033[92m'\n",
    "    red = '\\033[91m'\n",
    "    bold = '\\033[1m'\n",
    "    underline = '\\033[4m'\n",
    "    end = '\\033[0m'\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    deivce = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root='',\n",
    "    train=True, \n",
    "    download=False, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((32, 32)), # Resize image to fit LeNet-5\n",
    "        transforms.ToTensor() # Convert PIL.Images to torch.tensors\n",
    "    ])\n",
    ")\n",
    "\n",
    "dev_set = torchvision.datasets.MNIST(\n",
    "    root='', \n",
    "    train=False, \n",
    "    download=False, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((32, 32)), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet5(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(8, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_dp): Dropout2d(p=0.4, inplace=False)\n",
      "  (fc1): Linear(in_features=800, out_features=256, bias=True)\n",
      "  (fc1_dp): Dropout(p=0.4, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=84, bias=True)\n",
      "  (fc2_bn): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet5, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, 5) # ConvLayer 1 -> 1 input channel, 6 output channels, f=(5 x 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8, 32, 5) # ConvLayer 2 -> 6 input channels, 16 output channels, f=(5 x 5) \n",
    "        self.conv2_dp = nn.Dropout2d(0.4) # Dropout - keep_prob = 0.3\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(800, 256) # Fully connected layer 1 -> 400 | 120\n",
    "        self.fc1_dp = nn.Dropout(0.4) # Dropout - keep_prob = 0.4\n",
    "        self.fc2 = nn.Linear(256, 84) # Fully connected layer 2 -> 120 | 84\n",
    "        self.fc2_bn = nn.BatchNorm1d(84)\n",
    "        self.fc3 = nn.Linear(84, 10) # Output\n",
    "        \n",
    "    def forward(self, X):\n",
    "        A = F.relu(F.max_pool2d(self.conv1_bn(self.conv1(X)), 2)) # ReLU(Max_Pool()) -> stride=2\n",
    "        A = F.relu(F.max_pool2d(self.conv2_dp(self.conv2(A)), 2)) # ReLU(Max_Pool()) -> stride=2\n",
    "        \n",
    "        A = A.view(A.size()[0], -1) # Unroll the activation\n",
    "        \n",
    "        A = F.relu(self.fc1_dp(self.fc1(A))) # ReLU Activation on FC layer 1\n",
    "        A = F.relu(self.fc2_bn(self.fc2(A))) # ReLU Activation on FC layer 2\n",
    "        A = self.fc3(A) # Output\n",
    "        \n",
    "        return A\n",
    "    \n",
    "model = ConvNet5().to(device)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0033) # optimizer -> ADAM\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.79433)\n",
    "criterion = nn.CrossEntropyLoss() # loss function -> Cross-Entropy Loss\n",
    "counter = 0 # Set iteration counter to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1mEpoch 0:\u001b[0m\n",
      "Cost on iteration 0: 2.39416\n",
      "Cost on iteration 1000: 0.06976\n",
      "Cost on iteration 2000: 0.02448\n",
      "\u001b[92m\u001b[1mEpoch 20:\u001b[0m\n",
      "Cost on iteration 3000: 0.0144\n",
      "Cost on iteration 4000: 0.0168\n",
      "\u001b[92m\u001b[1mEpoch 40:\u001b[0m\n",
      "Cost on iteration 5000: 0.00925\n",
      "Cost on iteration 6000: 0.00215\n",
      "Cost on iteration 7000: 0.01486\n",
      "\u001b[92m\u001b[1mEpoch 60:\u001b[0m\n",
      "Cost on iteration 8000: 0.00391\n",
      "\u001b[1mCost on final iteration: 0.010450762696564198\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.train()\n",
    "\n",
    "constant = 1000 # interval for printing cost\n",
    "epochs = 70 # number of epochs\n",
    "epoch_constant = 20 # interval for printing epoch\n",
    "\n",
    "for e in range(epochs):\n",
    "    if e % epoch_constant == 0: print(designer.green + designer.bold + \"Epoch \" + str(e) + \":\" + designer.end)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=512, shuffle=True, num_workers=4)\n",
    "    for batch in train_loader:\n",
    "        X = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter % constant == 0:\n",
    "            print(\"Cost on iteration \" + str(counter) + \": \" + str(round(cost.item(), 5)))\n",
    "        counter += 1\n",
    "    \n",
    "    scheduler.step()\n",
    "if counter % constant != 0: print(designer.bold + \"Cost on final iteration: \" + str(cost.item()) + designer.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:57<00:00, 1035.90it/s]\n",
      "100%|██████████| 10000/10000 [00:09<00:00, 1035.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.96333%\n",
      "Dev Accuracy: 99.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "model.eval()\n",
    "\n",
    "# Train Evaluation\n",
    "examples = 60000\n",
    "counter = 0\n",
    "for i in tqdm(range(examples)):\n",
    "    X = train_set[i][0].to(device)\n",
    "    y = train_set[i][1]\n",
    "    \n",
    "    if model(X.view(1, 1, 32, 32)).argmax(1).item() == y:\n",
    "        counter += 1\n",
    "train_accuracy = counter / examples\n",
    "\n",
    "# CV Evaluation\n",
    "examples = 10000\n",
    "counter = 0\n",
    "for i in tqdm(range(examples)):\n",
    "    X = dev_set[i][0].to(device)\n",
    "    y = dev_set[i][1]\n",
    "    \n",
    "    if model(X.view(1, 1, 32, 32)).argmax(1).item() == y:\n",
    "        counter += 1\n",
    "dev_accuracy = counter / examples\n",
    "\n",
    "print(\"Train Accuracy: \" + str(round(train_accuracy * 100, 5)) + \"%\")\n",
    "print(\"Dev Accuracy: \" + str(round(dev_accuracy * 100, 5)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m\u001b[4mExample 349:\u001b[0m\n",
      "\u001b[92m\u001b[1mThe target(3) is equal to the hypothesis(3).\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "def mnister(x):\n",
    "    print(designer.purple + designer.bold + designer.underline + \"Example \" + str(x) + \":\" + designer.end)\n",
    "    \n",
    "    hypothesis = model(dev_set[x][0].view(1, 1, 32, 32).to(device)).argmax(1).item()\n",
    "    target = dev_set[x][1]\n",
    "    if target == hypothesis:\n",
    "        print(designer.green+designer.bold+\"The target(\"+str(target)+\") is equal to the hypothesis(\"+str(hypothesis)+\").\"+designer.end)\n",
    "    else:\n",
    "        print(designer.red+designer.bold+\"The target(\"+str(target)+\") is not equal to the hypothesis(\"+str(hypothesis)+\").\"+designer.end)\n",
    "        \n",
    "    plt.imshow(dev_set[x][0].squeeze(), cmap=\"gray\")\n",
    "    return plt.show()\n",
    "\n",
    "mnister(randint(1, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MNIST.prm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpuenv)",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
