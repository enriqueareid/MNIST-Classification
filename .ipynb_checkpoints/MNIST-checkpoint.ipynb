{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "from random import randint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "torch.set_printoptions(precision=8)\n",
    "\n",
    "# Printing Options\n",
    "class colors:\n",
    "    reset='\\033[0m'\n",
    "    bold='\\033[01m'\n",
    "    disable='\\033[02m'\n",
    "    underline='\\033[04m'\n",
    "    reverse='\\033[07m'\n",
    "    strikethrough='\\033[09m'\n",
    "    invisible='\\033[08m'\n",
    "    class fg:\n",
    "        black='\\033[30m'\n",
    "        red='\\033[31m'\n",
    "        green='\\033[32m'\n",
    "        orange='\\033[33m'\n",
    "        blue='\\033[34m'\n",
    "        purple='\\033[35m'\n",
    "        cyan='\\033[36m'\n",
    "        lightgrey='\\033[37m'\n",
    "        darkgrey='\\033[90m'\n",
    "        lightred='\\033[91m'\n",
    "        lightgreen='\\033[92m'\n",
    "        yellow='\\033[93m'\n",
    "        lightblue='\\033[94m'\n",
    "        pink='\\033[95m'\n",
    "        lightcyan='\\033[96m'\n",
    "    class bg:\n",
    "        black='\\033[40m'\n",
    "        red='\\033[41m'\n",
    "        green='\\033[42m'\n",
    "        orange='\\033[43m'\n",
    "        blue='\\033[44m'\n",
    "        purple='\\033[45m'\n",
    "        cyan='\\033[46m'\n",
    "        lightgrey='\\033[47m'\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    deivce = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root='',\n",
    "    train=True, \n",
    "    download=False, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((32, 32)), # Resize image to fit LeNet-5\n",
    "        transforms.ToTensor() # Convert PIL.Images to torch.tensors\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root='', \n",
    "    train=False, \n",
    "    download=False, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((32, 32)), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet5(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(8, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_dp): Dropout2d(p=0.4, inplace=False)\n",
      "  (fc1): Linear(in_features=800, out_features=256, bias=True)\n",
      "  (fc1_dp): Dropout(p=0.4, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=84, bias=True)\n",
      "  (fc2_bn): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet5, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, 5) # ConvLayer 1 -> 1 input channel, 6 output channels, f=(5 x 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8, 32, 5) # ConvLayer 2 -> 6 input channels, 16 output channels, f=(5 x 5) \n",
    "        self.conv2_dp = nn.Dropout2d(0.4) # Dropout - keep_prob = 0.3\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(800, 256) # Fully connected layer 1 -> 400 | 120\n",
    "        self.fc1_dp = nn.Dropout(0.4) # Dropout - keep_prob = 0.4\n",
    "        self.fc2 = nn.Linear(256, 84) # Fully connected layer 2 -> 120 | 84\n",
    "        self.fc2_bn = nn.BatchNorm1d(84)\n",
    "        self.fc3 = nn.Linear(84, 10) # Output\n",
    "        \n",
    "    def forward(self, X):\n",
    "        A = F.relu(F.max_pool2d(self.conv1_bn(self.conv1(X)), 2)) # ReLU(Max_Pool()) -> stride=2\n",
    "        A = F.relu(F.max_pool2d(self.conv2_dp(self.conv2(A)), 2)) # ReLU(Max_Pool()) -> stride=2\n",
    "        \n",
    "        A = A.view(A.size()[0], -1) # Unroll the activation\n",
    "        \n",
    "        A = F.relu(self.fc1_dp(self.fc1(A))) # ReLU Activation on FC layer 1\n",
    "        A = F.relu(self.fc2_bn(self.fc2(A))) # ReLU Activation on FC layer 2\n",
    "        A = self.fc3(A) # Output\n",
    "        \n",
    "        return A\n",
    "    \n",
    "model = ConvNet5().to(device)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0033) # optimizer -> ADAM\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.79433)\n",
    "criterion = nn.CrossEntropyLoss() # loss function -> Cross-Entropy Loss\n",
    "counter = 0 # Set iteration counter to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[01mEpoch 0:\u001b[0m\n",
      "Cost on iteration 0: 2.36912\n",
      "Cost on iteration 1000: 0.03504\n",
      "Cost on iteration 2000: 0.02639\n",
      "\u001b[32m\u001b[01mEpoch 20:\u001b[0m\n",
      "Cost on iteration 3000: 0.00365\n",
      "Cost on iteration 4000: 0.03174\n",
      "\u001b[32m\u001b[01mEpoch 40:\u001b[0m\n",
      "Cost on iteration 5000: 0.01407\n",
      "Cost on iteration 6000: 0.00765\n",
      "Cost on iteration 7000: 0.00687\n",
      "\u001b[32m\u001b[01mEpoch 60:\u001b[0m\n",
      "Cost on iteration 8000: 0.00634\n",
      "\u001b[01mCost on final iteration: 0.017301402986049652\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.train()\n",
    "\n",
    "constant = 1000 # interval for printing cost\n",
    "epochs = 70 # number of epochs\n",
    "epoch_constant = 20 # interval for printing epoch\n",
    "\n",
    "for e in range(epochs):\n",
    "    if e % epoch_constant == 0: print(colors.fg.green + colors.bold + \"Epoch \" + str(e) + \":\" + colors.reset)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=512, shuffle=True, num_workers=4)\n",
    "    for batch in train_loader:\n",
    "        X = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter % constant == 0:\n",
    "            print(\"Cost on iteration \" + str(counter) + \": \" + str(round(cost.item(), 5)))\n",
    "        counter += 1\n",
    "    \n",
    "    scheduler.step()\n",
    "if counter % constant != 0: print(colors.bold + \"Cost on final iteration: \" + str(cost.item()) + colors.reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60000/60000 [01:08<00:00, 878.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:11<00:00, 884.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.97167%\n",
      "Dev Accuracy: 99.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "model.eval()\n",
    "\n",
    "# Train Evaluation\n",
    "examples = 60000\n",
    "counter = 0\n",
    "for i in tqdm(range(examples)):\n",
    "    X = train_set[i][0].to(device)\n",
    "    y = train_set[i][1]\n",
    "    \n",
    "    if model(X.view(1, 1, 32, 32)).argmax(1).item() == y:\n",
    "        counter += 1\n",
    "train_accuracy = counter / examples\n",
    "\n",
    "# CV Evaluation\n",
    "examples = 10000\n",
    "counter = 0\n",
    "for i in tqdm(range(examples)):\n",
    "    X = test_set[i][0].to(device)\n",
    "    y = test_set[i][1]\n",
    "    \n",
    "    if model(X.view(1, 1, 32, 32)).argmax(1).item() == y:\n",
    "        counter += 1\n",
    "test_accuracy = counter / examples\n",
    "\n",
    "print(\"Train Accuracy: \" + str(round(train_accuracy * 100, 5)) + \"%\")\n",
    "print(\"Dev Accuracy: \" + str(round(test_accuracy * 100, 5)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[01m\u001b[04mExample 8909:\u001b[0m\n",
      "\u001b[32m\u001b[01mThe target(5) is equal to the hypothesis(5).\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "def mnister(x):\n",
    "    print(colors.fg.purple + colors.bold + colors.underline + \"Example \" + str(x) + \":\" + colors.reset)\n",
    "    \n",
    "    hypothesis = model(test_set[x][0].view(1, 1, 32, 32).to(device)).argmax(1).item()\n",
    "    target = test_set[x][1]\n",
    "    if target == hypothesis:\n",
    "        print(colors.fg.green+colors.bold+\"The target(\"+str(target)+\") is equal to the hypothesis(\"+str(hypothesis)+\").\"+colors.reset)\n",
    "    else:\n",
    "        print(colors.fg.red+colors.bold+\"The target(\"+str(target)+\") is not equal to the hypothesis(\"+str(hypothesis)+\").\"+colors.reset)\n",
    "        \n",
    "    plt.imshow(test_set[x][0].squeeze(), cmap=\"gray\")\n",
    "    return plt.show()\n",
    "\n",
    "mnister(randint(1, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MNIST.pt') # Save parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
